{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender systems. Content-based filtering\n",
    "\n",
    "## Motivation\n",
    "\n",
    "With collaborative filtering the recommendations were based in the ratings only. Content-based filtering recognizes there may be other information available about users or items that may improve the prediction. That information is represented as features about the items and the users.\n",
    "\n",
    "## Notation\n",
    "\n",
    "We have the following:\n",
    "\n",
    "* Features for usr j: $x_u^{(j)}$\n",
    "* Features for item i: $x_m^{(i)}$\n",
    "\n",
    "We predict rating of user j for item i as: \n",
    "\n",
    "$$v_u^{(j)} \\cdot v_m^{(i)}$$\n",
    "\n",
    "where $v_u^{(j)}$ and $v_m{(i)}$ are vectors of similar length derived from $x_u^{(j)}$ and $x_m^{(i)}$\n",
    "\n",
    "## Implementation with deep learning\n",
    "\n",
    "The vectors $v_u^{(j)}$ and $v_m{(i)}$ are the output of two neural networks that have $x_u^{(j)}$ and $x_m^{(i)}$ as their respective inputs and are training together by minimizing the cost function:\n",
    "\n",
    "$$J = \\sum_{(i, j):r(i,j)=1} (v_u^{(j)} \\cdot v_m^{(i)}-y^{(i, j)})^2 + \\text{neural network regularization term}$$\n",
    "\n",
    "To find similar items to item i:\n",
    "\n",
    "$$\\left\\Vert v_m^{(k)} - v_m^{(i)}\\right\\Vert^2 = \\sum_{l=1}^n (v_{m_l}^{(k)} - v_{m_l}^{(i)})^2$$\n",
    "\n",
    "## Recommending from a large set of items\n",
    "\n",
    "Two steps:\n",
    "\n",
    "* Retrieval: compile a list of pausible items by, for example (in a movie recommendation application):\n",
    "    * For each of the last 10 movies watched by user, select the 10 most similar movies\n",
    "    * For the 3 most viewed genres by the user, find the top 10 movies\n",
    "    * Top 20 movies in the country\n",
    "* Ranking\n",
    "    * Rank the list using the learned model\n",
    "\n",
    "## TensorFlow implementation\n",
    "\n",
    "### Input data format\n",
    "\n",
    "The TensorFlow implementation requires the input as follows:\n",
    "\n",
    "- Items: numpy array with one row per rating (combination of item and user), with the features of the item corresponding to that rating\n",
    "- Users: numpy array with one row per rating (combination of item and user), with the features of the user corresponding to that rating\n",
    "- Training set: one dimension numpy array with a sequence of ratings, corresponing to each row of the inputs\n",
    "\n",
    "### Code example\n",
    "\n",
    "``` python\n",
    "# User neural network\n",
    "\n",
    "user_NN = tf.keras.models.Sequential ([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32)\n",
    "]) \n",
    "\n",
    "# Item neural network\n",
    "\n",
    "user_NN = tf.keras.models.Sequential ([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(32)\n",
    "]) \n",
    "\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))   # Extracts the input features for the user\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)                         # Normalizes the vector vu to be equal to 1\n",
    "\n",
    "input_item = tf.keras.layers.Input(shape=(num_item_features))   # Extracts the input features for the user\n",
    "vm = item_NN(input_user)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)                         # Normalizes the vector vu to be equal to 1\n",
    "\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "model = Model([input_user, input_item], output)\n",
    "\n",
    "# Specify the cost function\n",
    "cost_fn = tf.keras.losses.MeanSquaredError ()\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 18:23:08.378556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "movies_vectors = pd.read_csv(\n",
    "    './data/MovieLensSimplified/content_item_train.csv', \n",
    "    header=None, \n",
    "    index_col=0,  # The movieId\n",
    "    names= ['year', 'ave rating', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Horror', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller'],\n",
    "    delimiter=',')\n",
    "users_vectors = pd.read_csv(\n",
    "    './data/MovieLensSimplified/content_user_train.csv', \n",
    "    header=None, \n",
    "    index_col=0, # The userId\n",
    "    names= ['rating count', 'rating ave', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Horror', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller'],\n",
    "    delimiter=',')\n",
    "y_df = pd.read_csv('./data/MovieLensSimplified/content_y_train.csv', header=None, delimiter=',')\n",
    "\n",
    "users_vectors.drop(columns=['rating count', 'rating ave'], inplace=True)\n",
    "\n",
    "movies = pd.read_csv(\n",
    "    \"./data/MovieLensSimplified/content_movie_list.csv\",\n",
    "    index_col='movieId',\n",
    ").rename(\n",
    "    columns={'title': 'title old'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-structure the info about movies\n",
    "\n",
    "# Extract year\n",
    "movies[['title', 'year']] = movies['title old'].str.extract('(.*)\\(([0-9]*)\\)$')\n",
    "\n",
    "# One hot encoding of genres\n",
    "genres = movies['genres'].str.get_dummies('|')\n",
    "movies = movies.join(genres)\n",
    "\n",
    "movies.drop(columns=['title old', 'genres'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50884, 16)\n",
      "(50884, 14)\n"
     ]
    }
   ],
   "source": [
    "print(movies_vectors.shape)\n",
    "print(users_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "num_user_features = users_vectors.shape[1] \n",
    "num_movie_features = movies_vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling \n",
    "\n",
    "movies_scaler = StandardScaler()\n",
    "movies_scaled = pd.DataFrame(\n",
    "    movies_scaler.fit_transform(movies_vectors),\n",
    "    index=movies_vectors.index,\n",
    "    columns=movies_vectors.columns\n",
    ")\n",
    "\n",
    "users_scaler = StandardScaler()\n",
    "users_scaled = pd.DataFrame(\n",
    "    users_scaler.fit_transform(users_vectors),\n",
    "    index=users_vectors.index,\n",
    "    columns=users_vectors.columns\n",
    ")\n",
    "\n",
    "\n",
    "y_scaler = MinMaxScaler((-1,1))\n",
    "y_scaled = pd.DataFrame(\n",
    "    y_scaler.fit_transform(y_df.to_numpy().reshape(-1,1)),\n",
    "    index=y_df.index,\n",
    "    columns=['rating']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40707, 16)\n",
      "(40707, 14)\n",
      "(40707, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split train, test\n",
    "\n",
    "movies_train, movies_test = train_test_split(movies_scaled, train_size=0.80, shuffle=True, random_state=1)\n",
    "users_train, users_test = train_test_split(users_scaled, train_size=0.80, shuffle=True, random_state=1)\n",
    "y_train, y_test = train_test_split(y_scaled, train_size=0.80, shuffle=True, random_state=1)\n",
    "\n",
    "print(movies_train.shape)\n",
    "print(users_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 18:24:23.652147: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512_VNNI\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-05 18:24:23.800233: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 14)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 16)]         0           []                               \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 32)           40864       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 32)           41376       ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize (TFOpLamb  (None, 32)          0           ['sequential[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.l2_normalize_1 (TFOpLa  (None, 32)          0           ['sequential_1[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 1)            0           ['tf.math.l2_normalize[0][0]',   \n",
      "                                                                  'tf.math.l2_normalize_1[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 82,240\n",
      "Trainable params: 82,240\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "\n",
    "num_outputs = 32\n",
    "tf.random.set_seed(1)\n",
    "user_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "item_NN = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(num_outputs)\n",
    "])\n",
    "\n",
    "# create the user input and point to the base network\n",
    "input_user = tf.keras.layers.Input(shape=(num_user_features))\n",
    "vu = user_NN(input_user)\n",
    "vu = tf.linalg.l2_normalize(vu, axis=1)\n",
    "\n",
    "# create the item input and point to the base network\n",
    "input_item = tf.keras.layers.Input(shape=(num_movie_features))\n",
    "vm = item_NN(input_item)\n",
    "vm = tf.linalg.l2_normalize(vm, axis=1)\n",
    "\n",
    "# compute the dot product of the two vectors vu and vm\n",
    "output = tf.keras.layers.Dot(axes=1)([vu, vm])\n",
    "\n",
    "# specify the inputs and output of the model\n",
    "model = tf.keras.Model([input_user, input_item], output)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.01),\n",
    "    loss=tf.keras.losses.MeanSquaredError()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1273/1273 [==============================] - 47s 29ms/step - loss: 0.1233\n",
      "Epoch 2/15\n",
      "1273/1273 [==============================] - 19s 15ms/step - loss: 0.1138\n",
      "Epoch 3/15\n",
      "1273/1273 [==============================] - 25s 20ms/step - loss: 0.1086\n",
      "Epoch 4/15\n",
      "1273/1273 [==============================] - 21s 17ms/step - loss: 0.1042\n",
      "Epoch 5/15\n",
      "1273/1273 [==============================] - 15s 12ms/step - loss: 0.1018\n",
      "Epoch 6/15\n",
      "1273/1273 [==============================] - 16s 12ms/step - loss: 0.0988\n",
      "Epoch 7/15\n",
      "1273/1273 [==============================] - 38s 30ms/step - loss: 0.0962\n",
      "Epoch 8/15\n",
      "1273/1273 [==============================] - 39s 31ms/step - loss: 0.0943\n",
      "Epoch 9/15\n",
      "1273/1273 [==============================] - 27s 21ms/step - loss: 0.0925\n",
      "Epoch 10/15\n",
      "1273/1273 [==============================] - 28s 22ms/step - loss: 0.0912\n",
      "Epoch 11/15\n",
      "1273/1273 [==============================] - 28s 22ms/step - loss: 0.0895\n",
      "Epoch 12/15\n",
      "1273/1273 [==============================] - 30s 23ms/step - loss: 0.0878\n",
      "Epoch 13/15\n",
      "1273/1273 [==============================] - 27s 21ms/step - loss: 0.0866\n",
      "Epoch 14/15\n",
      "1273/1273 [==============================] - 26s 20ms/step - loss: 0.0852\n",
      "Epoch 15/15\n",
      "1273/1273 [==============================] - 32s 25ms/step - loss: 0.0837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0bfa7b35e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "model.fit([users_train, movies_train], y_train, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 11s 25ms/step - loss: 0.0872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08724342286586761"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([users_test, movies_test], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1273/1273 [==============================] - 12s 9ms/step\n",
      "Accuracy train: 0.90\n"
     ]
    }
   ],
   "source": [
    "# Caculate accuracy on train set\n",
    "\n",
    "y_train_hat = model.predict([users_train, movies_train])\n",
    "ratings_train_hat = pd.DataFrame(\n",
    "    y_scaler.inverse_transform(y_train_hat),\n",
    "    index=y_train.index,\n",
    "    columns=['rating']\n",
    ")\n",
    "\n",
    "ratings_train = pd.DataFrame(\n",
    "    y_scaler.inverse_transform(y_train),\n",
    "    index=y_train.index,\n",
    "    columns=['rating']\n",
    ")\n",
    "\n",
    "accuracy_train = np.sum(np.abs(ratings_train['rating'] - ratings_train_hat['rating']) <= 1)/ratings_train.shape[0]\n",
    "\n",
    "print(f\"Accuracy train: {accuracy_train:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319/319 [==============================] - 3s 10ms/step\n",
      "Accuracy test: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy on test set\n",
    "\n",
    "y_test_hat = model.predict([users_test, movies_test])\n",
    "ratings_test_hat = pd.DataFrame(\n",
    "    y_scaler.inverse_transform(y_test_hat),\n",
    "    index=y_test.index,\n",
    "    columns=['rating']\n",
    ")\n",
    "\n",
    "ratings_test = pd.DataFrame(\n",
    "    y_scaler.inverse_transform(y_test),\n",
    "    index=y_test.index,\n",
    "    columns=['rating']\n",
    ")\n",
    "\n",
    "accuracy_test = np.sum(np.abs(ratings_test['rating'] - ratings_test_hat['rating']) <= 1)/ratings_test.shape[0]\n",
    "\n",
    "print(f\"Accuracy test: {accuracy_test:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damian/.local/lib/python3.8/site-packages/sklearn/base.py:420: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Recommendations for a user\n",
    "# The user likes adventure and fantasy movies\n",
    "\n",
    "user1_features = np.array([[0,5,0,0,0,0,0,0,5,0,0,0,0,0]])\n",
    "\n",
    "# This is the vector for the movies\n",
    "movies1_vectors = movies_vectors.drop_duplicates()\n",
    "\n",
    "# We will generate predictions for all the movies. This is the vector for the user\n",
    "user1_vectors = pd.DataFrame(np.repeat(user1_features, movies1_vectors.shape[0], axis=0))\n",
    "\n",
    "user1_vectors_s = users_scaler.transform(user1_vectors)\n",
    "movies1_vector_s = movies_scaler.transform(movies1_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 3s 78ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_ps = model.predict([user1_vectors_s, movies1_vector_s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_p = pd.DataFrame(\n",
    "    y_scaler.inverse_transform(y_ps),\n",
    "    columns=['rating'],\n",
    "    index = movies1_vectors.index\n",
    ")\n",
    "\n",
    "y_p = y_p.join(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81834</th>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>4.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108932</th>\n",
       "      <td>The Lego Movie</td>\n",
       "      <td>4.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122926</th>\n",
       "      <td>Untitled Spider-Man Reboot</td>\n",
       "      <td>4.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8368</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6283</th>\n",
       "      <td>Cowboy Bebop: The Movie (Cowboy Bebop: Tengoku...</td>\n",
       "      <td>3.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    title  rating\n",
       "81834       Harry Potter and the Deathly Hallows: Part 1     4.09\n",
       "108932                                    The Lego Movie     4.07\n",
       "122926                        Untitled Spider-Man Reboot     4.01\n",
       "8368            Harry Potter and the Prisoner of Azkaban     4.00\n",
       "6283    Cowboy Bebop: The Movie (Cowboy Bebop: Tengoku...    3.99"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_p[['title', 'rating']].sort_values(by='rating', ascending=False).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
